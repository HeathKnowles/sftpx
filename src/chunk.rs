use anyhow::Result;
use blake3::Hasher;
use prost::Message;
use std::fs::File;
use std::io::{BufReader, Read, BufWriter, Write};
/// 100 MB chunks
pub const CHUNK_SIZE: usize = 100 * 1024 * 1024;

// --------- PROTOBUF MODULE (AUTO-GENERATED BY build.rs) ------------
// IMPORTANT: You MUST change the filename below to whatever prost generated.
// Run:  ls target/debug/build/sftpx-*/out/
// Look for something like: sftpx.chunk.rs  or  chunk.rs
// Then change:
//     "/chunk.rs"
// to match your file.
// --------------------------------------------------------------------


use pb::{Chunk, ChunkTable};
use crate::pb;


/// Chunk a file into protobuf objects.
/// Splits file into 100MB blocks and hashes each one with blake3.
pub fn chunk_file_to_pb(path: &str) -> Result<ChunkTable> {
    let file = File::open(path)?;
    let metadata = file.metadata()?;
    let file_size = metadata.len();

    let mut reader = BufReader::new(file);
    let mut buffer = vec![0u8; CHUNK_SIZE];

    let mut chunks = Vec::new();
    let mut index: u64 = 0;
    let mut offset: u64 = 0;

    while offset < file_size {
        let to_read = std::cmp::min(CHUNK_SIZE as u64, file_size - offset) as usize;

        // Read chunk bytes
        let mut read_total = 0usize;
        while read_total < to_read {
            let n = reader.read(&mut buffer[read_total..to_read])?;
            if n == 0 {
                break;
            }
            read_total += n;
        }

        let chunk_bytes = buffer[..read_total].to_vec();

        // Compute blake3 hash
        let mut hasher = Hasher::new();
        hasher.update(&chunk_bytes);
        let out = hasher.finalize();
        let hash_hex = hex::encode(out.as_bytes());

        // Build protobuf Chunk
        let pb_chunk = Chunk {
            index,
            offset,
            data: chunk_bytes,
            hash_hex,
        };

        chunks.push(pb_chunk);

        offset += read_total as u64;
        index += 1;
    }

    // Build protobuf ChunkTable
    Ok(ChunkTable {
        file_size,
        chunk_size: CHUNK_SIZE as u64,
        chunks,
    })
}


/// Serialize the protobuf ChunkTable → bytes
pub fn serialize_chunk_table(table: &ChunkTable) -> Vec<u8> {
    table.encode_to_vec()
}

/// Deserialize bytes → protobuf ChunkTable
pub fn deserialize_chunk_table(bytes: &[u8]) -> Result<ChunkTable> {
    Ok(ChunkTable::decode(bytes)?)
}

pub fn reconstruct_file(table: &pb::ChunkTable, output: &str) -> Result<()> {
    let file = File::create(output)?;
    let mut writer = BufWriter::new(file);

    for chunk in &table.chunks {
        writer.write_all(&chunk.data)?;
    }

    writer.flush()?;
    Ok(())
}